<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PonderTTT: Adaptive Test-Time Training</title>
    <link rel="stylesheet" href="styles.css">
    <meta name="description" content="Adaptive, budget-aware Test-Time Training (TTT) for code generation models built with JAX/Flax NNX.">
    <!-- KaTeX for LaTeX rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css" integrity="sha384-WcoG4HRXMzYzfCgiyfrySxx90XSl2rxY5mnVY5TwtWE6KLrArNKn0T/mOgNL0Mmi" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.js" integrity="sha384-J+9dG2KMoiR9hqcFao0IBLwxt6zpcyN68IgwzsCSkbreXUjmNVRhPFTssqdSGjwQ" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
</head>
<body>

<div class="container">
    <header>
        <h1>PonderTTT</h1>
        <p class="subtitle">Adaptive, budget-aware Test-Time Training (TTT) for code generation models built with JAX/Flax NNX.</p>
        <div class="links">
            <a href="https://github.com/deveworld/ponderttt" class="btn">View on GitHub</a>
            <a href="PonderTTT_preprint.pdf" class="btn btn-outline">Read Preprint</a>
        </div>
    </header>

    <section id="core-idea">
        <h2>Core Idea: Binary Gating via Gumbel-Softmax</h2>
        <p>PonderTTT introduces <strong>Adaptive Test-Time Training</strong> with learned SKIP/UPDATE decisions. Instead of applying TTT updates uniformly to all input chunks, we learn <strong>when</strong> to update using a binary gating mechanism trained via Gumbel-Softmax.</p>
        
        <table>
            <thead>
                <tr>
                    <th>Feature</th>
                    <th>Fixed TTT</th>
                    <th>PonderTTT (Binary Gating)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Decision</strong></td>
                    <td>Always UPDATE</td>
                    <td>SKIP or UPDATE per chunk</td>
                </tr>
                <tr>
                    <td><strong>Training</strong></td>
                    <td>N/A</td>
                    <td>Gumbel-Softmax (differentiable)</td>
                </tr>
                <tr>
                    <td><strong>Inference</strong></td>
                    <td>Fixed cost</td>
                    <td>True computational savings</td>
                </tr>
                <tr>
                    <td><strong>Cost</strong></td>
                    <td>3.0x (UPDATE_1)</td>
                    <td>2.67x (83% update rate)</td>
                </tr>
            </tbody>
        </table>

        <h3>Key Results (GPT-2 125M on Python)</h3>
        <ul>
            <li><strong>4.5x perplexity improvement</strong> over non-adaptive baseline (26.36 â†’ 5.85)</li>
            <li><strong>Strong OOD generalization:</strong> JavaScript (2.5x), Java (6.2x), Go (70x)</li>
            <li>Learned policy captures universal "when to adapt" patterns</li>
        </ul>
    </section>

    <section id="technical-architecture">
        <h2>Technical Architecture</h2>
        <p>This project is a pure <strong>JAX/Flax NNX</strong> rewrite of the official TTT-LM, enhanced with adaptive gating.</p>
        <ul>
            <li><strong>Base Model:</strong> Pretrained GPT-2 (125M, 350M) with frozen backbone weights</li>
            <li><strong>Fast-Weight Layer (<code>TTTLayer</code>):</strong> TTT-Linear with causal convolutions and dual-form updates</li>
            <li><strong>Binary Gating Network:</strong> Lightweight MLP that makes SKIP/UPDATE decisions via Gumbel-Softmax</li>
            <li><strong>End-to-End Loss:</strong> \( L_{total} = L_{CE} + \beta \cdot L_{TTT} + \gamma \cdot L_{cost} \)</li>
        </ul>
    </section>

    <section id="roadmap">
        <h2>Roadmap & Status</h2>
        <p>The project is currently in active development. Phase 1 is complete with a preprint available.</p>
        
        <h3>Phase 1: Complete (Preprint)</h3>
        <ul>
            <li>Pure NNX GPT-2, TTT Layer with Binary Gating</li>
            <li>Gumbel-Softmax training for SKIP/UPDATE decisions</li>
            <li>End-to-End differentiable training with budget constraints</li>
            <li>Results on GPT-2 (125M, 350M) with OOD evaluation</li>
        </ul>

        <h3>Phase 2: Planned (Conference Submission)</h3>
        <p>See <code>PLAN.md</code> for detailed roadmap.</p>
        <ul>
            <li><strong>Scale to Gemma 3 (4B, 12B):</strong> Validate on modern, production-relevant architectures.</li>
            <li><strong>LoRA-TTT for Efficiency:</strong> Replace full TTT updates with Low-Rank Adaptation.</li>
            <li><strong>Reasoning Benchmarks:</strong> MATH500, GSM8K, LiveCodeBench, GPQA-Diamond.</li>
            <li><strong>Advanced Gating Features:</strong> Entropy, VOG, Attention Dispersion.</li>
        </ul>
    </section>

    <section id="quick-start">
        <h2>Quick Start</h2>
        
        <h3>Installation</h3>
        <pre><code># Install uv if you do not have it yet
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install the project in editable mode
uv pip install -e . --group gpu # or tpu/cpu</code></pre>

        <h3>Training Binary Gating</h3>
        <pre><code>python -m ponderttt.experiments.train_hard_skip \
    --model_scale 125m \
    --target_update_rate 0.5 \
    --num_iterations 10000 \
    --output_dir outputs/hard_skip</code></pre>

        <h3>Evaluation</h3>
        <pre><code>python -m ponderttt.experiments.compare_methods \
    --model_scale 125m \
    --budget 2.0 \
    --num_eval_batches 20</code></pre>
    </section>

    <section id="citation">
        <h2>Citation</h2>
        <div class="citation">@article{sim2025ponderttt,
  title={Learning to Ponder: Adaptive Compute Allocation via Test-Time Training},
  author={Sim, Gihyeon},
  year={2025}
}</div>
    </section>

    <footer>
        <p>&copy; 2025 PonderTTT Project. Built with JAX/Flax NNX.</p>
    </footer>
</div>

</body>
</html>
